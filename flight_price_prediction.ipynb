{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNd9zTozn4IWJWT+wxBpw8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavnautiyalDS/flight_price_prediction/blob/main/flight_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importing Libraries**"
      ],
      "metadata": {
        "id": "pWjVizc877rb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDq5WIMfQs8E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "xHTu-fmQuPgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/final flight dataset.csv\")\n",
        "df1=df.sample(1000)\n",
        "df2=df.sample(1000)\n",
        "\n",
        "df = pd.concat([df1, df2], axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "GUZxKS6Vz0Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Zqv4QFTtBJt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The columns ARRIVAL_TIME, Duration, and DATE_OF_JOURNEY_2 can be dropped because Dep_Time is already represented in DEPARTURE_TIME and ARRIVAL_TIME, Duration is covered in DURATIONMIN, and the information from DEPARTURE_TIME is also captured in ARRIVAL_TIME.**"
      ],
      "metadata": {
        "id": "B67DaQEC69nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df.drop(['ARRIVAL_TIME','Duration','DATE_OF_JOURNEY_2','Dep_Time'],inplace=True,axis=1)\n"
      ],
      "metadata": {
        "id": "-kxUQ7OvV0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, I will extract the day of travel and month of travel from DEPARTURE_TIME, and the time of day from Dep_Time.**"
      ],
      "metadata": {
        "id": "sF_RpaDA7Swa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert DEPARTURE_TIME to datetime\n",
        "df['DEPARTURE_TIME'] = pd.to_datetime(df['DEPARTURE_TIME'])\n",
        "\n",
        "# Extract day and month\n",
        "df['Day'] = df['DEPARTURE_TIME'].dt.day\n",
        "df['Month'] = df['DEPARTURE_TIME'].dt.month\n",
        "df['DayOfweek']=df['DEPARTURE_TIME'].dt.day_name()"
      ],
      "metadata": {
        "id": "9Tg-NbZN1VrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "xwha99dR1MaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, I will create a new feature called daytime by categorizing Dep_Time into time slots: Morning, Afternoon, Evening, Night, and Midnight.**"
      ],
      "metadata": {
        "id": "-pGzC7ak7iKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now i fill make daytime: Morning, afternoon, everning,night, midnight\n",
        "# Extract hour\n",
        "df['Hour'] = df['DEPARTURE_TIME'].dt.hour\n",
        "# Define function to categorize time of day\n",
        "def get_daytime(hour):\n",
        "    if 5 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 17:\n",
        "        return 'Afternoon'\n",
        "    elif 17 <= hour < 21:\n",
        "        return 'Evening'\n",
        "    elif 21 <= hour <= 23:\n",
        "        return 'Night'\n",
        "    else:  # 0 <= hour < 5\n",
        "        return 'Midnight'\n",
        "\n",
        "# Apply function to create DayTime column\n",
        "df['DayTime'] = df['Hour'].apply(get_daytime)\n"
      ],
      "metadata": {
        "id": "UEPeskRY2Cg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "DYvo3gLj2fca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now remove DEPARTURE_TIME\n",
        "df.drop('DEPARTURE_TIME',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "b0ZIDdOi2iKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Hour',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "HenOWkHw3AEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Durationmin in hour**"
      ],
      "metadata": {
        "id": "kWaML7b17mmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Durationmin in hour\n",
        "df['DURATIONHour']=df['DURATIONMIN']/60"
      ],
      "metadata": {
        "id": "7kalo-lC-vS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['DURATIONHour']=df['DURATIONHour'].astype('int')"
      ],
      "metadata": {
        "id": "cJi01IaW-31z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('DURATIONMIN',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "G-LCzMZw_RUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Endoding**\n"
      ],
      "metadata": {
        "id": "z2Asgqpl7xdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this i have used one-hot-encoding"
      ],
      "metadata": {
        "id": "UEjopkWh8L4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing\n",
        "\n",
        "cat_cols = ['Airline', 'Source', 'Destination','Total_Stops','DayOfweek','DayTime']\n",
        "df_label_encoded=df.copy()\n",
        "\n",
        "# One-Hot Encode with binary format (0/1)\n",
        "df_label_encoded= pd.get_dummies(df, columns=cat_cols, drop_first=True).astype('int')  # drop_first=True to avoid dummy variable trap\n",
        "\n"
      ],
      "metadata": {
        "id": "UEWBI-2FyGwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_encoded"
      ],
      "metadata": {
        "id": "VQMy2zC7zJ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reorder columns to move 'Price' to the last\n",
        "cols = [col for col in df_label_encoded.columns if col != 'Price'] + ['Price']\n",
        "df_label_encoded = pd.DataFrame(df_label_encoded[cols])\n",
        "\n",
        "# Display resuld\n",
        "df_label_encoded\n"
      ],
      "metadata": {
        "id": "cscTSnlpyWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Scaling**"
      ],
      "metadata": {
        "id": "SoDsIuz0yGa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this i have used min-max scaling"
      ],
      "metadata": {
        "id": "NpHQEmIN8U_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# List numeric columns you want to scale\n",
        "num_cols = ['DURATIONHour', 'Price','Month','Day']  # replace/add other numerical column names if needed\n",
        "\n",
        "# Apply min-max scaling and replace in DataFrame\n",
        "df_label_encoded[num_cols] = scaler.fit_transform(df_label_encoded[num_cols])\n",
        "\n",
        "# Display the scaled DataFram\n",
        "df_label_encoded.head()"
      ],
      "metadata": {
        "id": "ykIZr_TCzfG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model splitting**"
      ],
      "metadata": {
        "id": "t40qfi762nHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X = df_label_encoded.drop('Price', axis=1)\n",
        "y = df_label_encoded['Price']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "aas0HWVg2ouw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "def Evaluation_Metrics_Regression(model_object, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Evaluate a regression model with key metrics.\n",
        "    \"\"\"\n",
        "    Y_pred = model_object.predict(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'R2 Score': r2_score(Y_test, Y_pred),\n",
        "        'MAE': mean_absolute_error(Y_test, Y_pred),\n",
        "        'MSE': mean_squared_error(Y_test, Y_pred),\n",
        "        'RMSE': mean_squared_error(Y_test, Y_pred)**(0.5)\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n"
      ],
      "metadata": {
        "id": "_2C4HWPL2f1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection**"
      ],
      "metadata": {
        "id": "RIXZPA818ac2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(25,15))\n",
        "sns.heatmap(df_label_encoded.corr(),annot=True)"
      ],
      "metadata": {
        "id": "OwhpRVJa_tij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **lasso regression**"
      ],
      "metadata": {
        "id": "l-JsEzp18eOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#using lasso regression\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and target\n",
        "X = df_label_encoded.drop('Price', axis=1)\n",
        "y = df_label_encoded['Price']\n",
        "\n",
        "\n",
        "\n",
        "# Try multiple alpha values\n",
        "alphas = [0.0001, 0.001, 0.01,0.1]\n",
        "\n",
        "# Dictionary to store coefficients\n",
        "coef_dict = {}\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso = Lasso(alpha=alpha)\n",
        "    lasso.fit(X, y)\n",
        "    coef_dict[f'alpha_{alpha}'] = lasso.coef_\n",
        "\n",
        "# Create DataFrame with features as index and alphas as columns\n",
        "coef_variation_df = pd.DataFrame(coef_dict, index=X.columns)\n",
        "\n",
        "# Optionally, round for neatness\n",
        "coef_variation_df = coef_variation_df.round(4)\n",
        "\n",
        "# Show how coefficients vary with alpha\n",
        "coef_variation_df\n"
      ],
      "metadata": {
        "id": "eATpgqM3zwVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonimportant_features1=set(['Airline_GoAir','Airline_Multiple carriers Premium economy','Airline_Vistara Premium economy','Total_Stops_3 stops'])"
      ],
      "metadata": {
        "id": "J_L1G3ZbBixg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Wrapping Method**"
      ],
      "metadata": {
        "id": "7iztmNq8_GOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Sequential Feature Selector (Forward selection)\n",
        "sfs = SequentialFeatureSelector(estimator=model,\n",
        "                                n_features_to_select=5,\n",
        "                                direction='forward',\n",
        "                                scoring='r2',\n",
        "                                cv=5)\n",
        "\n",
        "sfs.fit(X_train, Y_train)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = X_train.columns[sfs.get_support()]\n",
        "\n",
        "nonimportant_features=set([i for i in X_train.columns if i not in selected_features])\n"
      ],
      "metadata": {
        "id": "fYsN2rrvCGoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonimportant_features1.intersection(nonimportant_features)"
      ],
      "metadata": {
        "id": "xa0YSE_WNshU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping common columns\n",
        "df_label_encoded.drop(nonimportant_features1.intersection(nonimportant_features),axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "qKrRkk46C7aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_encoded"
      ],
      "metadata": {
        "id": "V_O2Y1_BDROZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evaulation Metrics and Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "jIjCTYneDaDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "def Evaluation_Metrics_Regression(model_object, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Evaluate a regression model with key metrics.\n",
        "    \"\"\"\n",
        "    Y_pred = model_object.predict(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'R2 Score': r2_score(Y_test, Y_pred),\n",
        "        'MAE': mean_absolute_error(Y_test, Y_pred),\n",
        "        'MSE': mean_squared_error(Y_test, Y_pred),\n",
        "        'RMSE': mean_squared_error(Y_test, Y_pred)**(0.5)\n",
        "    }\n",
        "    sns.scatterplot(x=Y_test,y=Y_pred,color='red')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "    return pd.DataFrame.from_dict(metrics, orient='index', columns=['Score'])\n"
      ],
      "metadata": {
        "id": "1BgX5oABDxMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def HyperparameterTuning(X, y, model_name, search_type='grid', n_iter_random=10):\n",
        "    # Select model and hyperparameter grid\n",
        "    if model_name == LR:\n",
        "        model = LinearRegression()\n",
        "        param_grid = {\n",
        "            'fit_intercept': [True, False],\n",
        "        }\n",
        "\n",
        "    elif model_name == DT:\n",
        "        model = DecisionTreeRegressor(random_state=42)\n",
        "        param_grid = {\n",
        "            'max_depth': [3, 5, 10, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "\n",
        "    elif model_name == RF:\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "        param_grid = {\n",
        "            'n_estimators': [50, 100, 150],\n",
        "            'max_depth': [5, 10, 20, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name. Choose from 'LR', 'DTR', or 'RFR'.\")\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    if search_type == 'grid':\n",
        "        search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "    elif search_type == 'random':\n",
        "        search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=n_iter_random, cv=5, scoring='r2', random_state=42, n_jobs=-1)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid search_type. Choose 'grid' or 'random'.\")\n",
        "\n",
        "    # Fit and get best model/params\n",
        "    search.fit(X, y)\n",
        "    best_model = search.best_estimator_\n",
        "    best_params = search.best_params_\n",
        "\n",
        "    return best_model, best_params\n"
      ],
      "metadata": {
        "id": "OJVTERYNEsq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LINER REGRESSION**"
      ],
      "metadata": {
        "id": "eu5xFgE522gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR=LinearRegression()\n",
        "LR.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "gln6fR0624ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(LR, X_train, Y_train))"
      ],
      "metadata": {
        "id": "A4BOEBzM3IlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(LR, X_test, Y_test))"
      ],
      "metadata": {
        "id": "LGlSuYTMEsWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "cWcixX3EF9v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HyperparameterTuning(X_train, Y_train, LR, search_type='grid', n_iter_random=10)"
      ],
      "metadata": {
        "id": "zz7_0oBmGA4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrain my model on best parameter**"
      ],
      "metadata": {
        "id": "szrwjTROHCQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR1=LinearRegression(fit_intercept=False)\n",
        "LR1.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "Zb1IoAcSHHd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(LR1, X_train, Y_train))\n"
      ],
      "metadata": {
        "id": "trRbUu7BHPFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DecisionTreeRegressor**"
      ],
      "metadata": {
        "id": "crV59A-eHgfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DT=DecisionTreeRegressor()\n",
        "DT.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "5ooOecw83zxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(DT, X_train, Y_train))"
      ],
      "metadata": {
        "id": "mUpPb2fSE3Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(DT, X_test, Y_test))"
      ],
      "metadata": {
        "id": "KpjbCS-E37lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparamter tuning**"
      ],
      "metadata": {
        "id": "h0KbIeFUHuRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HyperparameterTuning(X_train, Y_train, DT, search_type='grid', n_iter_random=10)"
      ],
      "metadata": {
        "id": "Kcre_VVEHyqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrain my model on best paramters**"
      ],
      "metadata": {
        "id": "DnKm6jO_IAld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DT1=DecisionTreeRegressor(max_depth= None, min_samples_leaf= 1, min_samples_split= 2)\n",
        "DT1.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "wHaUylXDIIA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After Tuning\",Evaluation_Metrics_Regression(DT1, X_test, Y_test))"
      ],
      "metadata": {
        "id": "V9umHbOjIU5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Tuning\",Evaluation_Metrics_Regression(DT, X_test, Y_test))"
      ],
      "metadata": {
        "id": "RK8O3lBZIo4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RandomForestReggressor**"
      ],
      "metadata": {
        "id": "ab9Be2ZbIvzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF=RandomForestRegressor()\n",
        "RF.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "PyG9WWA4396f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(RF, X_train, Y_train))"
      ],
      "metadata": {
        "id": "2aaeAEG-E8iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluation_Metrics_Regression(RF, X_test, Y_test))"
      ],
      "metadata": {
        "id": "h1wzRJTL4CIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "tepBGRHgJAu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HyperparameterTuning(X_train, Y_train, RF, search_type='grid', n_iter_random=10)"
      ],
      "metadata": {
        "id": "mn_Z8dDZWsE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrain my model after hyperparameter tuning**"
      ],
      "metadata": {
        "id": "2R6_ABwNJ8xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF1=RandomForestRegressor(n_estimators=150,max_depth=None,\n",
        "  min_samples_leaf=1,\n",
        "  min_samples_split= 2,\n",
        "  )\n",
        "RF1.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "O46Fjc-GKAyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After tuning\",Evaluation_Metrics_Regression(RF1, X_test, Y_test))"
      ],
      "metadata": {
        "id": "ialnWIhtKYVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before tuning\",Evaluation_Metrics_Regression(RF, X_test, Y_test))"
      ],
      "metadata": {
        "id": "CtiYyVwmKd3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of the three models I trained, Linear Regression had the lowest R² score. Decision Tree achieved the highest score, but it's overfitting as there's a significant difference between the training and testing performance. Therefore, Random Forest is the best-performing and most balanced model, and I will select it for final deployment."
      ],
      "metadata": {
        "id": "S7KCPVQkKvKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving pickle file**"
      ],
      "metadata": {
        "id": "2IkiqKWILfiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('FarePrediction.pkl', 'wb') as file:\n",
        "    pickle.dump(RF1, file)\n"
      ],
      "metadata": {
        "id": "jwFO_B-IXZ9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_encoded.columns"
      ],
      "metadata": {
        "id": "O0iKNzaRMo5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}